2025-01-23 13:18

Status:

Tags:[[Intelligence Interactive Systems]]

---

### *Note:*
*Not too important, just introductions. Can be mostly ignored.*

**Key Points:**
- **Required Reading every week**
- **2 Lectures per week**
- **Mix of HCI and AI, focus on essays and writing more then problem solving.**

### Introduction

Describes many of the different applications of AI that interact with humans such as translations, recommendation systems, automated driving, ChatGPT and LLM's etc,

Via these interactions (perception- action, conversational, decision), these intelligent systems should constantly verify and learn more information in order to lead to better outputs and interactions. This learning requires the use of models that learn from preferences and behaviour
### Responsible AI

Big part of lecture is going through the issues associated with AI. Issues including:
- **Purposeful Misinformation**: Whether that be through Deep fakes, cyber attacks
- **Misunderstanding of technology**: Paranoia of AI taking over systems
- **AI in use of human critical activities**: Whether it be autonomous vehicles or autopilot or managing important systems, it will need to handle them in ways "humans" would accept. The trolley problem is a good example not even being divisive regarding this.
- **Uncontrolled Stops**: With AI's with an excessive amount of access to important systems, physical, manual immediate stops must be in place, with the AI being closely monitored to not behaving in a undesired matter 
- **Biases (LLM's)** : Since the input for LLM's come from texts written by humans, it will contain biases, which will only be pronounced further by the LLM when receives multiple occurrences of that biases.
- **Hallucination (LLM's)**:  Can come up with completely fake or incredibly misleading information. But can be mitigated with *retrieval assisted generation (RAG)* where it only gets data from accompanying document.
- Intellectual Property(LLM): 
- **Adversarial Attacks**: In the case of LLM's you can technically get any information, so arm race between developers and hackers to jail break it to get any information.

### Technologies


- **Large Language Models**: Predicts next word based on probability.
- **Perceptron:** Computes weighted sum of inputs but limited in expressivity (e.g., cannot learn XOR)
- **Word embedders e.g. (Word2Vec):** Algorithms that map words into continuous vector spaces where semantically similar words are placed closer together, improving representation over one-hot encoding
- **Recurrent Neural Nets**: Models designed to process sequences by incorporating information from previous inputs, though difficult to train due to vanishing gradients
- **Transformers:** Sequence models that rely solely on attention mechanisms, enabling efficient parallel processing and achieving state-of-the-art results in NLP tasks

##### Glossary
---

##### References
----
[Assessments](file:///C:/Users/Asus/Documents/School/Final_Year/Intelligent_Interactive_Systems/Week_1/Assessment.pdf)
[Introductions](file:///C:/Users/Asus/Documents/School/Final_Year/Intelligent_Interactive_Systems/Week_1/Introduction.pdf)![[Introduction.pdf]]
[Responsible AI](file:///C:/Users/Asus/Documents/School/Final_Year/Intelligent_Interactive_Systems/Week_1/ResponsibleAI%20without%20Video.pdf)![[ResponsibleAI without Video.pdf]]